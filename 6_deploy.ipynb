{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Deploying and predicting with model </h1>\n",
    "\n",
    "This notebook illustrates:\n",
    "<ol>\n",
    "<li> Deploying model\n",
    "<li> Predicting with model\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change these to try this notebook out\n",
    "BUCKET = 'qwiklabs-gcp-e6c6fe8dd7979408'\n",
    "PROJECT = 'qwiklabs-gcp-e6c6fe8dd7979408'\n",
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['TFVERSION'] = '1.7'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if ! gsutil ls | grep -q gs://${BUCKET}/; then\n",
    "  gsutil mb -l ${REGION} gs://${BUCKET}\n",
    "  # copy canonical model if you didn't do previous notebook\n",
    "  gsutil -m cp -R gs://cloud-training-demos/babyweight/trained_model gs://${BUCKET}/babyweight/trained_model\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Deploy trained model </h2>\n",
    "<p>\n",
    "Deploying the trained model to act as a REST web service is a simple gcloud call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://qwiklabs-gcp-e6c6fe8dd7979408/babyweight/trained_model/export/exporter/\n",
      "gs://qwiklabs-gcp-e6c6fe8dd7979408/babyweight/trained_model/export/exporter/1536188147/\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gsutil ls gs://${BUCKET}/babyweight/trained_model/export/exporter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting and deploying babyweight ml_on_gcp from gs://qwiklabs-gcp-e6c6fe8dd7979408/babyweight/trained_model/export/exporter/1536188147/ ... this will take a few minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created ml engine model [projects/qwiklabs-gcp-e6c6fe8dd7979408/models/babyweight].\n",
      "Creating version (this might take a few minutes)......\n",
      "...............................................................................................................................................................................................................................................................................................................................................................................................................................................done.\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "MODEL_NAME=\"babyweight\"\n",
    "MODEL_VERSION=\"ml_on_gcp\"\n",
    "MODEL_LOCATION=$(gsutil ls gs://${BUCKET}/babyweight/trained_model/export/exporter/ | tail -1)\n",
    "echo \"Deleting and deploying $MODEL_NAME $MODEL_VERSION from $MODEL_LOCATION ... this will take a few minutes\"\n",
    "#gcloud ml-engine versions delete ${MODEL_VERSION} --model ${MODEL_NAME}\n",
    "#gcloud ml-engine models delete ${MODEL_NAME}\n",
    "gcloud ml-engine models create ${MODEL_NAME} --regions $REGION\n",
    "gcloud ml-engine versions create ${MODEL_VERSION} --model ${MODEL_NAME} --origin ${MODEL_LOCATION} --runtime-version $TFVERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Use model to predict (online prediction) </h2>\n",
    "<p>\n",
    "Send a JSON request to the endpoint of the service to make it predict a baby's weight. The order of the responses are the order of the instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"predictions\": [{\"predictions\": [0.6718437671661377], \"key\": [\"b1\"]}, {\"predictions\": [0.28848713636398315], \"key\": [\"g1\"]}, {\"predictions\": [0.24402552843093872], \"key\": [\"b2\"]}, {\"predictions\": [0.2945956289768219], \"key\": [\"u1\"]}]}\n"
     ]
    }
   ],
   "source": [
    "from oauth2client.client import GoogleCredentials\n",
    "import requests\n",
    "import json\n",
    "\n",
    "MODEL_NAME = 'babyweight'\n",
    "MODEL_VERSION = 'ml_on_gcp'\n",
    "\n",
    "token = GoogleCredentials.get_application_default().get_access_token().access_token\n",
    "api = 'https://ml.googleapis.com/v1/projects/{}/models/{}/versions/{}:predict' \\\n",
    "         .format(PROJECT, MODEL_NAME, MODEL_VERSION)\n",
    "headers = {'Authorization': 'Bearer ' + token }\n",
    "data = {\n",
    "  'instances': [\n",
    "    {\n",
    "      'key': 'b1',\n",
    "      'is_male': 'True',\n",
    "      'mother_age': 26.0,\n",
    "      'plurality': 'Single(1)',\n",
    "      'gestation_weeks': 39\n",
    "    },\n",
    "    {\n",
    "      'key': 'g1',\n",
    "      'is_male': 'False',\n",
    "      'mother_age': 29.0,\n",
    "      'plurality': 'Single(1)',\n",
    "      'gestation_weeks': 38\n",
    "    },\n",
    "    {\n",
    "      'key': 'b2',\n",
    "      'is_male': 'True',\n",
    "      'mother_age': 26.0,\n",
    "      'plurality': 'Triplets(3)',\n",
    "      'gestation_weeks': 39\n",
    "    },\n",
    "    {\n",
    "      'key': 'u1',\n",
    "      'is_male': 'Unknown',\n",
    "      'mother_age': 29.0,\n",
    "      'plurality': 'Multiple(2+)',\n",
    "      'gestation_weeks': 38\n",
    "    },\n",
    "  ]\n",
    "}\n",
    "response = requests.post(api, json=data, headers=headers)\n",
    "print response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions for the four instances were: 7.66, 7.22, 6.32 and 6.19 pounds respectively when I ran it (your results might be different)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Use model to predict (batch prediction) </h2>\n",
    "<p>\n",
    "Batch prediction is commonly used when you thousands to millions of predictions.\n",
    "Create a file withe one instance per line and submit using gcloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting inputs.json\n"
     ]
    }
   ],
   "source": [
    "%writefile inputs.json\n",
    "{\"key\": \"b1\", \"is_male\": \"True\", \"mother_age\": 26.0, \"plurality\": \"Single(1)\", \"gestation_weeks\": 39}\n",
    "{\"key\": \"g1\", \"is_male\": \"False\", \"mother_age\": 26.0, \"plurality\": \"Single(1)\", \"gestation_weeks\": 39}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobId: babypred_180905_232429\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://inputs.json [Content-Type=application/json]...\n",
      "/ [0 files][    0.0 B/  204.0 B]                                                \r",
      "/ [1 files][  204.0 B/  204.0 B]                                                \r\n",
      "Operation completed over 1 objects/204.0 B.                                      \n",
      "CommandException: 1 files/objects could not be removed.\n",
      "Job [babypred_180905_232429] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe babypred_180905_232429\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs babypred_180905_232429\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "INPUT=gs://${BUCKET}/babyweight/batchpred/inputs.json\n",
    "OUTPUT=gs://${BUCKET}/babyweight/batchpred/outputs\n",
    "gsutil cp inputs.json $INPUT\n",
    "gsutil -m rm -rf $OUTPUT \n",
    "gcloud ml-engine jobs submit prediction babypred_$(date -u +%y%m%d_%H%M%S) \\\n",
    "  --data-format=TEXT --region ${REGION} \\\n",
    "  --input-paths=$INPUT \\\n",
    "  --output-path=$OUTPUT \\\n",
    "  --model=babyweight --version=ml_on_gcp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2017 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
